操作系统期中考试复习
------------------

## 第一讲
#### 操作系统定义
- 操作系统是一个控制程序
- 操作系统是一个资源管理器
- 软件->系统软件->操作系统->命令行/内核

#### 操作系统软件的组成
- shell：命令行入口
- GUI：图形用户接口
- kernel：操作系统内部

#### 操作系统内核的特征
- 并发（多进程）
- 共享
- 虚拟（每个用户都觉得有一个计算机专门为他服务）
- 异步（运行环境相同则程序运行结果相同）

- - -

## 第二讲
#### x86-32硬件
##### 80386的运行模式
- 实模式
	- 80386加电启动后处于实模式
	- 软件可访问物理内存空间不超过1MB
	- 不使用段页式管理
- 保护模式
	- 支持内存分页机制，提供对虚拟内存的良好支持
	- 支持多任务和优先级机制（共4个级别，优先级0最高）
	- 实现任务的数据安全共享和隔离

##### 80386的内存架构
- 32位处理器，可寻址的物理内存空间为4G（2^32)
- 物理地址
	- 处理器提交到总线上用于访问计算机系统中的内存和外设的最终地址
	- 一个计算机系统中只有一个物理地址
- 线性地址
	- 在操作系统的虚存管理之下每个进程能访问的地址空间
	- 每个进程都认为自己独享整个计算机系统的地址空间
	- 可以让多个进程相互隔离
- 逻辑地址
	- 应用程序直接使用的地址空间
- 段机制启动、页机制未启动：逻辑地址->段机制处理->线性地址=物理地址
- 段机制和页机制都启动：逻辑地址->段机制处理->线性地址->页机制处理->物理地址

##### 80386的寄存器
- 通用寄存器
- 段寄存器
- 指令寄存器
	- EIP：指令寄存器，存储下一条要执行的指令的内存地址（分段地址转换中，表示指令的段内偏移地址）
	- EFLAGS：标志寄存器

- - - 

## 第三讲
#### 启动时计算机内存和磁盘布局
- CS：IP=0xf0000:fff0
	- CS：代码段寄存器；IP：指令指针寄存器
- 系统处于式模式
- PC=16*CS+IP
- 20位地址空间：1MB
- 基本输入输出的程序，系统设置信息，开机自检程序，系统自启动程序

#### 加载程序的内存地址空间
- BIOS：
	- 讲加载程序从磁盘的引导扇区（512字节）加载到0x7c00
	- 跳转到CS：IP=0000:7C00
- 加载程序：
    - 将操作系统的代码和数据从硬盘加载到内存中
    - 跳转到操作系统的起始地址
- BIOS系统调用：
    - BIOS以中断调用的方式提供了基本的IO功能
    - 只能在x86的实模式下访问

#### 计算机启动流程
1. 系统加电，BIOS初始化硬件
2. BIOS读取主引导扇区代码
3. 主引导扇区代码读取活动分区的引导扇区代码
4. 引导扇区代码读取文件系统的加载程序

#### CPU初始化
- CPU加电稳定后从0xffff0读第一条指令
    - CS：IP=0xf000:fff0
    - 第一条指令是跳转指令
- CPU初始状态是16位实模式
    - CS：IP是16位寄存器
    - 指令指针PC=16*CS+IP
    - 最大地址空间是1MB

#### BIOS初始化
- 硬件自检
- 执行系统BIOS，进行系统检测
- 更新CMOS中的扩展系统配置数据ESCD
- 按指定启动顺序从软盘、硬盘或光驱启动

#### 主引导记录MBR格式
- 启动代码：446字节
    - 检查分区表正确性
    - 加载并跳转到磁盘上的引导程序
- 硬盘分区表：64字节
    - 描述分区状态和位置
    - 每个分区描述信息占据16字节
- 结束标志字：2字节（55AA）

#### 分区引导扇区格式
- 跳转指令（跳转到启动代码）+文件卷头+启动代码（跳转到加载程序）+结束标志（55AA）

#### 加载程序（bootloader）
- 加载程序：从文件系统中读取启动配置信息
- 启动菜单：可选的操作系统内核列表和加载参数
- 操作系统内核：一句配置加载指定内核并跳转到内核执行

#### 中断、异常和系统调用
- 系统调用
	- 应用程序主动向操作系统发出的服务请求
	- 来源：应用程序请求操作系统提供服务
	- 异步或同步
	- 处理：等待和持续
- 异常
	- 非法指令或者其它原因导致当前指令执行失败后的处理请求
	- 来源：应用程序意想不到的行为
	- 同步
	- 处理：杀死或重新执行意想不到的应用程序指令
- 中断
	- 来自硬件设备的处理请求
	- 来源：外设
	- 异步
	- 处理：持续，对用户应用程序是透明的

#### 中断处理机制
- 硬件：在CPU初始化时设置中断使能标志
	- 依据内部或外部事件设置中断标志
	- 依据中断向量调用相应中断服务例程
- 软件：
	- 编译器：现场保存
	- 服务例程：中断服务处理
	- 服务例程：清楚中断标记
	- 编译器：现场恢复
- 中断嵌套
	- 硬件中断服务例程可被打断（出现硬件中断）
	- 异常服务例程可被打断（出现硬件中断）
	- 异常服务例程可嵌套（例程中出现缺页）

#### 系统调用
- 例子：输出时（例如printf）会触发系统调用write()
- 系统调用
	- 操作系统服务的编程接口
	- 通常由高级语言编写（C或C++）
	- 程序访问通常通过高层次的API接口而不是直接进行系统调用
- 实现
	- 每个系统调用对应一个系统调用号
	- 系统调用接口调用内核态的系统调用功能实现，并返回系统调用的状态和结果
	- 用户不需要知道系统调用的实现
- 系统调用与函数调用的不同处
	- 系统调用：IRET、INT
	- 会发生堆栈切换和特权级的切换
	- 函数调用：CALL、RET
	- 没有堆栈切换

#### 中断、异常、系统调用的开销
- 比函数开销大
- 开销来源：
	- 引导机制
	- 建立内核堆栈
	- 验证参数
	- 内核态映射到用户态地址空间（更新页面映射权限）
	- 内核态独立地址空间（TLB）

- - -

## 第五讲
#### 操作系统的内存管理
- 抽象、保护、共享、虚拟化
- 操作系统采用的内存管理方式
	- 重定位
	- 分段
	- 分页
	- 虚拟存储
- 实现高度依赖硬件

#### 地址空间定义
- 物理地址空间：硬件支持的地址空间
- 逻辑地址空间：在CPU运行的进程看到的地址
- 逻辑地址生成：编译->汇编->链接->程序加载（重定位）
- 地址生成的时机和限制：
	- 编译时：假设起始地址已知。若起始地址改变则需重新编译
	- 加载时：编译时起始地址未知，编译器需生成可重定位的代码。加载时生成绝对地址
	- 执行时：执行时代码可移动，需要地址转换（映射）硬件支持

#### 地址生成过程：
- CPU：ALU需要逻辑地址的内存内容，MMU进行逻辑地址和物理地址的转换，CPU控制逻辑给总线发送物理地址
- 内存：发送物理地址的内容给CPU或接收CPU数据到物理地址
- 操作系统：建立逻辑地址和物理地址的映射

#### 连续内存分配和内存碎片
- 连续内存分配：给进程分配一块不小于指定大小的连续的物理内存区域
- 内存碎片：空闲内存不能被利用
- 外部碎片：分配单元之间的未被使用内存
- 内部碎片：分配单元内部的未被使用内存

#### 连续内存分配：动态分区分配
- 当程序被加载执行时分配一个进程指定的大小可变的分区（地址连续）
- 操作系统需要维护的数据结构：所有进程的已分配分区；空闲分区
- 动态分区分配策略：最先分配，最佳分配，最差分配

#### 分配策略的优缺点
- 最先分配
	- 简单，在高地址空间有大块的空闲分区
	- 外部碎片，分配大块较慢
- 最佳分配
	- 大部分分配的尺寸较小时效果很好，相对简单
	- 外部碎片，释放分区慢，容易产生很多无用的小碎片
- 最差分配
	- 中等大小的分配较多时，效果最好，避免出现太多的小碎片
	- 释放分区较慢，外部碎片，容易破坏大的空闲分区，后续难以分配大的分区

#### 碎片整理：紧凑
- 碎片整理：通过调整进程占用的分区位置来减少或避免分区碎片
- 紧凑：通过移动分配给进程的分区，合并外部碎片
	- 条件：所有的应用程序可以动态重定位
	- 问题：什么时候移动，开销
- 分区对换：通过抢占并回收处于等待状态进程的分区，来增大可用内存空间
	- 把用户地址空间的进程移动到外存中
	- 问题：交换哪些程序

#### 伙伴系统
- 整个可分配的分区大小为 2^U^
- 需要的分区大小为 2^U-1^ < s <= 2^U^ 时，把整个块分配给该进程
	- 若s <= 2^i-1^，将大小为2^i^的当前空闲分区划分成两个大小为2^i-1^d的空闲分区
	- 重复划分过程，直到2^i-1^<s<=2^i^，并把一个空闲分区分配给该进程
- 实现：数据结构
	- 空闲块按大小和起始地址组织成二维数组
	- 初始状态：只有一个大小为2^U^的空闲块
- 分配过程：
	- 由小到大在空闲块数组中最好最小的可用空闲块
	- 若空闲块过大，对可用空闲块进行二分，直到得到合适的可用空闲块

- - -

## 第六讲
#### 非连续内存分配
- 连续分配的缺点：
	- 分配给程序的物理内存必须连续
	- 存在外碎片和内碎片
	- 内存分配的动态修改较难
	- 内存利用率较低
- 非连续分配的设计目标：提高内存利用效率和管理灵活性
	- 允许一个程序使用非连续的的物理地址空间
	- 允许共享代码和数据
	- 支持动态加载和动态链接
- 问题：如何实现虚拟地址和物理地址的转换
	- 软件实现：灵活，开销大
	- 硬件实现：够用，开销小
- 非连续分配的硬件辅助机制
	- 如何选择非连续分配中的内存分块大小：段式存储管理、页式存储管理

#### 段式存储管理
- 由多个段组成
	- 主代码段、子模块代码段、公用库代码段、堆栈段、堆数据、初始化数据段、符号表etc
- 段式存储的目的
	- 更细粒度和灵活的分离与共享
- 不连续二维结构
- 段表示访问方式和存储数据等属性相同的一段地址空间，对应一个连续的内存“块”。若干个段组成进程逻辑地址空间
- 段访问的逻辑地址由段号和段内偏移表示

#### 页式存储管理
- 页帧：把物理地址空间划分为大小相同的基本分配单位
- 页面：把逻辑地址空间划分为相同大小的基本分配单位
- 页面到页帧：逻辑地址到物理地址的转换（页表，MMU/TLB）
- 内存物理地址表示：帧号+帧内偏移（2^帧大小^*帧号+帧内偏移量）
- 内存逻辑地址表示：页号+页内偏移（2^页大小^*页号+页内偏移量）
	- 页内偏移=帧内偏移
	- 通常页号大小 != 帧号大小
- 逻辑地址中的页号是连续的，物理地址中的帧号是不连续的
- 不是所有的页都有对应的帧

##### 页表
- 页表保存了逻辑地址到物理地址之间的映射关系
- 每个进程都有一个页表
	- 每个页面对应一个页表项
	- 随进程运行状态而动态变化
	- 页表基址由页表基址寄存器（PTBR）保存
	- 页表项标志：存在位、修改位、引用位

##### 页式存储管理机制的性能问题
- 内存访问性能问题
	- 访问一个内存单元要两次内存访问（获取页表项&访问数据）
- 页表大小问题
	- 页表可能非常大
- 如何处理
	- 缓存(Caching)
	- 间接访问
- 快表（TLB）
	- 缓存近期访问的页表项
	- 使用关联存储，可以快速访问
	- 如果TLB命中，则物理页号可以很快获取
	- 如果TLB未命中，对应表项被更新到TLB中
	- 快表在CPU中
- 多级页表
	- 建立页表树，减少每级页表的长度
- 大地址空间问题
	- 对64bits系统，多级页表变得繁琐，逻辑地址空间增长速度快于物理地址空间
	- 不让页表与逻辑地址空间大小相对应，让页表与物理地址空间大小相对应
- 页寄存器
	- 每个帧与一个页寄存器关联
	- 页寄存器中包含使用位（此帧是否被进程占用），占用页号（页号p），保护位
	- 优点：页表大小相对于物理内存而言很小，页表大小与逻辑地址空间大小无关
	- 缺点：页表信息对调后，需要依据帧号找页号，在页寄存器中搜索逻辑地址中的页号（？）

##### 页寄存器中的地址转换
- CPU生成的逻辑地址如何找对应的物理地址？
	- 对逻辑地址进行hash映射
	- 需要解决可能的冲突
- 用快表缓存页表项后的页寄存器搜索步骤
	- 对逻辑地址进行Hash变换
	- 在快表中查找对应页表项
	- 有冲突时遍历冲突项链表
	- 查找失败时产生异常
- 快表的限制
	- 快表的容量限制
	- 快表的功能限制（功耗大）

##### 反置页表
- 基于Hash映射值查找对应页表项中的帧号
	- 进程表示与页号的Hash值可能有冲突
	- 页表项中包括保护位、修改位、访问位和存在位等标识

#### 段页式存储管理的需求
- 段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势
- 在段式存储管理基础上，给每个段加一级页表
- 段页式存储管理中的内存共享
	- 通过指向相同的页表基址，实现进程间的段共享
	- 共享段共用同一页表，指向同一块物理内存

- - -

## 第八讲
#### 虚拟存储
- 需求：程序规模的增长速度远远大于存储器容量的增长速度，导致内存空间不够用
- 解决方法
	- 覆盖：应用程序手动把需要的指令和数据保存在内存中
	- 交换：操作系统把暂时不能自动执行的程序保存到外存中
	- 虚拟存储：在有限容量的内存中，以页为单位自动装入更多更大的程序
- 覆盖
	- 目标：在较小的可用内存中运行较大的程序
	- 实现方法：依据程序逻辑结构，将程序划分为若干功能相对独立的模块；将不会同时执行的模块共享同一块内存区域
	- 必要部分（常用功能）的代码和数据常驻内存，可选部分（不常用功能）放在其它程序模块中，只在需要用到时装入内存，不存在调用关系的模块可互相覆盖，共用同一块内存区域
	- 不足：增加编程困难，增加执行时间（时间换空间）
- 交换
	- 目标：增加正在运行或需要运行的程序的内存
	- 实现方法：将暂时不能运行的程序放到外存中
	- 换入换出的基本单位：整个进程的地址空间
	- 换出(swap out)：把一个进程的整个地址空间保存到外存
	- 换入(swap in)：将外存中某进程的地址空间读入到内存
	- 问题：
	- 交换时机：只当内存空间不够或有不够的可能时换出
	- 交换区大小：存放所有用户进程的所有内存映像的拷贝
	- 程序换入时的重定位：换出后再换入要放在原位吗？采用动态地址映射的方法（？）
- 覆盖与交换的比较
	- 覆盖：只能发生在没有调用关系的模块间，程序员需给出模块间的逻辑覆盖结构，发生在运行程序的内部模块间
	- 交换：以进程为单位，不需要模块间的逻辑覆盖结构，发生在内存进程间
- 虚拟存储技术的目标：
	- 只把部分程序放到内存中，从而运行比物理内存大的程序（操作系统完成，无需程序员的干涉）
	- 实现进程与内存与外存之间的交换，从而获得更多的空闲内存空间（在内存和外存之间只交换进程的部分内容）

#### 局部性原理
- 程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域
	- 时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下一次访问都几种在一个较短时间内
	- 空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内
	- 分支局部性：一条跳转指令的两次执行，很可能跳转到相同的内存位置
- 意义
	- 从理论上来说，虚拟存储就是能够实现，而且可以取得满意的效果

#### 虚拟存储的基本概念
- 思路：将不常用的部分内存块暂存到外存
- 原理：
	- 装载程序时只将当前指令执行需要的部分页面或段装入内存
	- 指令执行中需要的指令或数据不在内存（缺页或缺段）时，处理器通知操作系统将相应的页面或段调入内存
	- 操作系统将内存中暂时不用的页面或段保存到外存
- 实现方式：虚拟页式存储，虚拟段式存储
- 基本特征：
	- 不连续性（物理内存分配非连续，虚拟地址空间使用非连续）
	- 大用户空间（提供给用户的虚拟内存大于实际的物理内存）
	- 部分交换（虚拟内存只对部分虚拟地址空间进行调入和调出）
- 支持技术
	- 硬件：页式或短时存储中的地址转换机制
	- 操作系统：管理内存和外存间页面或段的换入和换出
- 虚拟页式存储管理：
	- 在页式存储管理的基础上，增加请求调页和页面置换
	- 当用户程序要装载到内存运行时，只装入部分页面，就启动程序运行
	- 进程在运行中发现有需要的代码或数据不在内存时，则向系统发出缺页异常请求
	- 操作系统在处理缺页一次时，将外存中相应的页面调入内存，使得进程能继续运行
- 虚拟页式存储中断页表项结构
	- 驻留位：1表示在内存中，0表示在外存中
	- 修改位：若被修改过，则回收时要把它的内容写回外存
	- 访问位：用于页面置换算法
	- 保护位：只读、可读写、可执行等
- 缺页异常处理流程
	A 在内存中有空闲物理页面时，分配一物理页帧f，转E
	B 依据页面置换算法选择将被替换的物理页帧f，对应逻辑页q
	C 如q被修改过，则将它写回外存
	D 修改q的页表项中驻留位置为0
	E 将需要访问的页p装入到物理页面f
	F 修改p的页表项驻留位为1，物理页帧号为f
	G 重新执行产生缺页的指令
- 虚拟页式存储中的外存管理
	- 要求能方便地找到在外存中的页面内容
	- 设置交换空间（采用特殊格式存储未被映射的页面）
- 虚拟页式存储中的外存选择
	- 代码段：可执行二进制文件
	- 动态加载的共享库程序段：动态调用的库文件
	- 其它段：交换空间（？）
- 性能
	- 有效存储访问时间EAT = 访存时间 * (1-p) + 缺页异常处理时间 * 缺页率p

- - -

## 第九讲
#### 置换算法
- 功能
	- 当出现缺页异常时，需调入新页面而内存已满时，置换算法选择被置换的物理页面
- 目标
	- 尽可能减少页面的调入调出次数
	- 把未来不再访问或短期内不访问的页面调出
- 页面锁定
	- 描述必须常驻内存的逻辑页面
	- 操作系统的关键部分
	- 要求相应速度的代码和数据
	- 页表中的锁定标志位(lock bit)
- 置换算法的评价方法
	 - 更少的缺页，更好的性能

#### 局部页面置换算法
置换页面的选择范围仅限于当前进程占用的物理页面

##### 最优算法OPT
- 置换在未来最长时间不访问的页面
- 缺页最少，理想情况，实际系统无法实现（无法预知每个页面在下次访问前的等待时间）
- 作为置换算法的性能评价依据

##### 先进先出算法FIFO
- 选择在内存驻留时间最长的页面进行置换
- 维护一个记录所有位于内存中的逻辑页面链表，按驻留内存时间排序，链首最长，链尾最短，出现缺页时选择链首页面进行置换，新页面加入到链尾
- 实现简单，性能较差（调出的页面可能是经常访问），有belady现象，较少单独使用

##### 最近最久未使用算法LRU
- 选择最长时间没有被引用的页面进行置换
- 缺页时，选择上一次使用到当前时间最长的页面
- 最优算法的一种近似
- 实现方法：页面链表
	- 系统维护一个按最近一次访问时间排序的页面链表，链表首节点是最近刚使用过的页面，链表尾节点是最久未使用的页面。
	- 访问内存时，找到相应页面，把它移动到链表首
	- 缺页时，置换链表尾节点的页面
- 实现方法：活动页面栈
	- 访问页面时，将此页号压入栈顶，并将栈内相同的页号抽出
	- 缺页时，置换栈底的页面
- 开销比较大

##### 时钟算法Clock
- 仅对页面的访问情况进行大致统计
- 在页表项中增加访问位，描述页面在过去一段时间内的访问情况。缺页时，从指针开始顺序查找未被访问的页面进行置换
- LRU和FIFO的折中
- 实现
	- 页面装入内存时，访问位初始化为0
	- 访问页面时，访问位置1
	- 缺页时，从指针当前位置顺序检查环形链：
	- 若访问位为0，则置换该页，访问位置1，指针移动到下一个页面
	- 若访问位为1，则访问位置0，指针移动到下一个页面
- 改进的clock算法：
	- 减少修改位的缺页处理开销
	- 在页面中增加修改位，并在访问时进行相应修改；缺页时，修改页面标志位，以跳过有修改的页面

##### 最不常用算法LFU
- 缺页时，置换访问次数最少的页面
- 每个页面设置一个访问计数，访问页面时访问计数加1，缺页时置换计数最小的页面
- 算法开销大，开始时频繁使用，但以后不使用的页面很难置换（解决方法：计数定期右移）
- 与LRU的区别：一个关注多久未访问，一个关注访问次数

##### Belady现象
- 分配的物理页面数增加，缺页次数反而升高的异常现象
- FIFO和clock都有belady现象，LRU没有

#### 全局页面置换算法
置换页面的选择范围是所有可换出的物理页面
- 为进程分配可变数目的物理页面
- 需要确定分配给进程的物理页面数
- CPU利用率与并发进程数存在相互促进和制约的关系（先高后低）

##### 工作集算法
- 工作集：一个进程当前正在使用的逻辑页面集合，可以表示为二元函数W(t,delta)
	- t是当前的执行时刻
	- delta是工作集窗口，即一个定长的页面访问时间窗口
	- W(t,delta)是指当前时刻t前的delta时间窗口中的所有访问页面所组成的集合
	- 工作集的大小即页面数目
	- 进程开始工作后，随着访问新页面逐步建立较稳定的工作集
	- 当内存访问的局部性区域的位置大致稳定时，工作集的大小也大致稳定
	- 局部性区域的位置改变时，工作集快速扩张和收缩，过渡到下一个稳定值
- 常驻集：当前时刻，进程实际驻留在内存当中的页面集合
	- 工作集是进程在运行时固有的性质，常驻集取决于系统分配给进程的物理页面数目和页面置换算法
	- 常驻集包含工作集时，缺页较少
	- 工作集发生剧烈变动时，缺页较多
	- 进程常驻集大小达到一定数目后，缺页率也不会明显下降
- 工作集置换算法
	- 换出不在工作集中的页面
	- 窗口大小tao
	- 实现方法：维护窗口内的访问页面链表，访存时，换出不再工作集中的页面，更新访存链表；缺页时换入页面，更新访存链表
- 缺页率：缺页次数/内存访问次数 或 缺页平均时间间隔的倒数
- 影响缺页率的因素：
	- 页面置换算法
	- 分配给进程的物理页面数
	- 页面大小
	- 程序的编写方法

##### 缺页率算法
- 通过调节常驻集大小，使每个进程的缺页率保持在一个合理的范围内
	- 若进程缺页率过高，则增加常驻集以分配更多的物理页面
	- 若进程缺页率过低，则减少常驻集以减少它的物理页面数
- 实现
	- 访存时，设置引用位标
	- 缺页时，计算从上次缺页时间t_last到现在t_current的时间间隔
	- 若t_current-t_last>T，则置换所有在[t_last, t_current]时间内没有被引用的页
	- 若t_current-t_last<=T，则增加缺失页到工作集中

#### 抖动问题
- 抖动
	- 进程物理页面太少，不能包含工作集
	- 造成大量缺页，频繁置换
	- 进程运行速度变慢
- 产生抖动的原因
	- 随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减少，缺页率不断上升
- 操作系统需在并发水平和缺页率之间达到一个平衡
	- 选择一个适当的进程数目和进程需要的物理页面数

#### 负载控制
- 通过调节并发进程数（MPL）来进行系统负载控制
	- sigma（WSI）=内存的大小
	- 平均缺页时间（MTBF）=缺页异常处理时间（PFST）

- - -

## 第十一讲
#### 进程
- 进程是指一个具有一定独立功能的程序在一个数据集合上的一次动态执行的过程
- 进程的组成
	- 代码
	- 数据
	- 状态寄存器（CPU状态CR0，指令指针IP）
	- 通用寄存器（AX，BX， CX……）
	- 进程占用系统资源（打开文件，已分配内存）
- 进程的特点
	- 动态：动态创建、结束
	- 并发：进程可被独立调度并占用处理机运行
	- 独立：不同进程的工作不互相影响
	- 制约：因访问共享数据、资源或进程间同步而产生制约
- 进程和程序的联系
	- 进程是操作系统处于执行状态程序的抽象
	- 同一个程序的多次执行过程对应多个进程
	- 进程执行需要来自内存的资源（保存代码和数据）和来自CPU的资源（执行指令）
- 进程和程序的区别
	- 进程是动态的，程序是静态
	- 程序是有序代码的集合。进程是程序的执行，进程有核心态和用户态。
	- 进程是暂时的，程序是永久的。进程是一个状态变化的过程，程序可长久保存
	- 进程的组成包括程序、数据和进程控制块

#### 进程控制块PCB
- 操作系统管理控制进程运行所用的信息集合
	- 操作系统用PCB来描述进程的基本情况以及运行变化的过程
	- PCB是进程存在的唯一标志，每个进程都在操作系统有一个对应的PCB
- 进程控制块的使用
	- 进程创建：生成该进程的PCB
	- 进程终止：回收它的PCB
	- 进程的组织管理：通过对PCB的组织管理来实现
- 进程控制信息
	- 调度和状态信息：调度进程和处理机使用情况
	- 进程间通信信息：进程间通信相关的各种标识
	- 存储管理信息：指向进程映像存储空间数据结构
	- 进程所用资源：进程使用的系统资源，如打开文件等
	- 有关数据结构连接信息：与PCB相关的进程队列
- 进程控制块的组织
	- 链表：同一状态的进程的PCB成一链表，多个状态对应多个不同的链表
	- 各状态的进程形成不同的链表，如就绪链表、阻塞链表等
	- 索引表：同一状态的进程归入一个索引表（索引指向PCB），多个状态对应多个不同的索引表
	- 各状态的进程形成不同的索引表：就绪索引表，阻塞索引表等

#### 进程的生命周期
- 进程创建
	- 系统初始化时
	- 用户请求创建一个新进程
	- 正在运行的进程执行了创建进程的系统调用（fork）
- 进程执行
	- 内核选择一个就绪的程序，让它占用处理机并执行
- 进程等待
	- 进程进入等待（阻塞）的情况：
	- 请求并等待系统服务，无法马上完成
	- 启动某种操作，无法马上完成
	- 需要的数据没有到达
	- 只有进程自身才能知道何时需要等待某种事件的发生
- 进程抢占
	- 高优先级进程就绪
	- 进程执行当前时间用完
- 进程唤醒
	- 被阻塞进程需要的资源可被满足
	- 被阻塞进程等待的事件到达
	- 进程只能被别的进程或操作系统唤醒
- 进程结束
	- 正常退出（自愿的）
	- 错误退出（自愿的）
	- 致命错误（强制性的）
	- 被其它进程所杀（强制性的）
- 进程切换
	- 保存现场
	- 产生中断（比如定时时间到）
	- 恢复现场

#### 三状态进程模型
- *运行状态（running）
	- 进程正在处理机上运行
- *就绪状态（ready）
	- 进程获得了除处理机之外的所需资源，得到处理机即可运行
- *等待状态（阻塞状态blocked）
	- 进程正在等待某一事件的出现而暂停运行
- 创建状态（new）
	- 一个进程正在被创建，还没被转到就绪状态之前的状态
- 结束状态（exit）
	- 一个进程正在从系统中消失时的状态，这是因为进程结束或由于其它原因所导致

#### 进程状态间切换
- NULL->新建
	- 一个新进程被产生出来执行一个程序
- 创建->就绪
	- 当进程被创建完成后并初始化后，一切就绪准备运行时，变为就绪状态
- 就绪->运行
	- 处于就绪状态的进程被进程调度程序选中后，分配到处理机上来运行
- 运行->结束
	- 当进程表示它已经完成或者出错时，当前运行进程会由操作系统作结束处理
- 运行->就绪
	- 处于运行状态的进程在运行过程中，由于分配给它的处理机时间片用完而让出处理机
- 运行->等待
	- 当进程请求某资源且必须等待时
- 等待->就绪
	- 当进程要等待的时间到来时，从阻塞状态变为就绪状态

#### 进程挂起
- 挂起：把一个进程从内存转到外存
- 激活：把一个进程从外存转到内存
- 处在挂起状态的进程映像在磁盘上，目的是减少进程占用内存
- 等待挂起状态
	- 进程在外存并等待某事件的出现
- 就绪挂起状态
	- 进程在外存，但只要进入内存，即可执行
- 等待到等待挂起
	- 没有进程处于就绪状态或就绪进程要求更多的内存资源
- 就绪到就绪挂起
	- 当有高优先级等待（系统认为会很快就绪的）进程和低优先级就绪进程时
- 运行到就绪挂起
	- 对抢先式分时系统，当有高优先级等待挂起进程因事件出现而进入就绪挂起
- 等待挂起到就绪挂起
	- 当有等待挂起进程因相关事件出现
- 就绪挂起到就绪
	- 没有就绪进程或挂起就绪进程优先级高于就绪进程
- 等待挂起到等待
	- 当一个进程释放足够内存，并有高优先级等待挂起进程

#### 状态队列
- 由操作系统来维护一组队列，表示系统中所有进程的当前状态
- 不同队列表示不同状态
	- 就绪队列、各种等待队列
- 根据进程状态不同，进程PCB加入相应队列
	- 进程状态变换，它所在的PCB会从一个队列换到另一个

#### 线程
- 线程是进程中的指令执行流的最小单元，是CPU调度的基本单位
- 进程的资源分配角色：进程由一组相关资源构成，包括地址空间、打开的文件等
- 线程的处理机调度角色：线程描述在进程资源环境中的指令流执行状态
- 线程=进程-共享资源
- 线程的优点
	- 一个进程中可以同时存在多个线程
	- 各个线程之间可以并发执行
	- 各个线程之间可以共享地址空间和文件等资源
- 线程的缺点
	- 一个线程崩溃，会导致其所属进程的所有线程崩溃
- 线程与进程的比较
	- 进程是资源分配单位，线程是CPU调度单位
	- 进程拥有一个完整的资源平台，而线程只独享指令流执行的必要资源，如寄存器和栈
	- 线程具有就绪、等待和运行三种基本状态和状态间的转换关系
	- 线程能减少并发执行的时间和空间开销
	- 线程的创建时间比进程短
	- 线程的终止时间比进程短
	- 同一进程内的线程切换时间比进程短
	- 由于同一进程的各线程间共享内存和文件资源，可不通过内核进行直接通信
- 用户线程
	- 在用户空间实现
	- 由一组用户级的线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等
	- 不依赖与操作系统的内核，内核不了解用户线程的存在，可用于不支持线程的多进程操作系统
	- 在用户空间实现的线程机制。每个进程有私有的线程控制块（TCB）列表，TCB由线程库函数维护
	- 同一进程内的用户线程切换速度快（无需用户态、内核态切换）
	- 允许每个进程拥有自己的线程调度算法
	- 线程发起系统调用而阻塞时，整个进程都进入等待
	- 不支持基于线程的处理器抢占，除非当前运行进程主动放弃，否则它所在进程的其它线程无法抢占CPU
	- 只能按进程分配CPU时间。多个线程进程中，每个线程的时间片较少
- 内核线程
	- 在内核中实现
	- 由内核通过系统调用实现的线程机制，由内核完成线程的创建、终止和管理
	- 由内核维护PCB和TCB
	- 线程执行系统调用而被阻塞不影响其它线程
	- 线程的创建、终止和切换相对较大
	- 通过系统调用内核函数，在内核实现切换
	- 咦线程为单位进行CPU时间分配，多线程的进程可以获得更多CPU时间
- 轻量级线程
	- 在内核中实现，支持用户线程
	- 内核支持的用户线程。一个进程可以有一个或多个轻量级进程，每个轻权进程由一个单独的内核线程来支持




